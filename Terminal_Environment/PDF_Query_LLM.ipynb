{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlorSbccWEDa"
      },
      "outputs": [],
      "source": [
        "%pip install langchain\n",
        "%pip install openai\n",
        "%pip install PyPDF2\n",
        "%pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nq0vKGFeW1KD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import pinecone\n",
        "from rate_limiter import Api\n",
        "from uuid import uuid4\n",
        "from dotenv import load_dotenv\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS\n",
        "from helpers import save_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yKaKB_GjWKjL"
      },
      "outputs": [],
      "source": [
        "# Get your API keys from openai, you will need to create an account. \n",
        "load_dotenv()\n",
        "openai.organization = os.getenv(\"org_openai\")\n",
        "openai.api_key = os.getenv(\"key_openai\")\n",
        "\n",
        "pinecone.init(api_key=os.getenv(\"key_pinecone\"), environment=os.getenv(\"env_pinecone\"))\n",
        "vdb = pinecone.Index(os.getenv(\"idx_pinecone\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NalD3XkQWrJR"
      },
      "outputs": [],
      "source": [
        "# location of the pdf file/files.\n",
        "locations = [\n",
        "  'C:/Users/shaj6/Documents/Programming/repositories/chairGPT/assets/2022 Annual Report.pdf',\n",
        "  'C:/Users/shaj6/Documents/Programming/repositories/chairGPT/assets/2021 Annual Report.pdf',\n",
        "  'C:/Users/shaj6/Documents/Programming/repositories/chairGPT/assets/2021-lululemon-impact-report-03-09-22.pdf',\n",
        "  'C:/Users/shaj6/Documents/Programming/repositories/chairGPT/assets/code-of-conduct-november-2021-english.pdf'\n",
        "]\n",
        "sharepoint_ids = [\n",
        "  '01AN3S6T4BLWNDAPLXJBC26M2IXIJMOSO6',\n",
        "  '01AN3S6T5PCLJNN6ZQMVFZZIMPQ7QTWMEY',\n",
        "  '01AN3S6TZ7CBBRLN4EHNAK7YK4EM2UIFUS',\n",
        "  '01AN3S6T27MGH4MALVAZDL4I2P72ZSTYF2'\n",
        "]\n",
        "readers = []\n",
        "for loc in locations:\n",
        "    readers.append(PdfReader(loc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwbEBhd0ZUfX",
        "outputId": "03542b02-bbc2-4c2a-def0-cae133e0b9f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<PyPDF2._reader.PdfReader at 0x1e18426fa90>,\n",
              " <PyPDF2._reader.PdfReader at 0x1e18426fa00>,\n",
              " <PyPDF2._reader.PdfReader at 0x1e18426fbb0>,\n",
              " <PyPDF2._reader.PdfReader at 0x1e1f3924ca0>]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "readers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2VXlucKiW7bX"
      },
      "outputs": [],
      "source": [
        "# read data from the file and put them into a variable called raw_text\n",
        "files = []\n",
        "for idx, reader in enumerate(readers):\n",
        "    raw_text = ''\n",
        "    for i, page in enumerate(reader.pages):\n",
        "        text = page.extract_text()\n",
        "        if text:\n",
        "            raw_text += text\n",
        "    obj = {'raw_text':raw_text, 'sharepoint_id':sharepoint_ids[idx]}\n",
        "    files.append(obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97262\n"
          ]
        }
      ],
      "source": [
        "print(len(files[0]['raw_text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VdXzkpf9XAfP"
      },
      "outputs": [],
      "source": [
        "# Chunk input text\n",
        "text_splitter = CharacterTextSplitter(      \n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "for file in files:\n",
        "    raw_text = file['raw_text']\n",
        "    file['chunks'] = text_splitter.split_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozkNTiNuZ0TX",
        "outputId": "dd800c23-e6fb-401a-ba22-1bb4a6b7d854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "338\n",
            "951.0118343195267\n"
          ]
        }
      ],
      "source": [
        "chunk_count = 0\n",
        "char_count = 0\n",
        "for file in files:\n",
        "  chunk_count += len(file['chunks'])\n",
        "  for chunk in file['chunks']:\n",
        "    char_count += len(chunk)\n",
        "print(chunk_count)\n",
        "print(char_count / chunk_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TcZUsQVyXBPX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File 01AN3S6T4BLWNDAPLXJBC26M2IXIJMOSO6, chunk 0\n",
            "File 01AN3S6T4BLWNDAPLXJBC26M2IXIJMOSO6, chunk 50\n",
            "File 01AN3S6T4BLWNDAPLXJBC26M2IXIJMOSO6, chunk 100\n",
            "File 01AN3S6T4BLWNDAPLXJBC26M2IXIJMOSO6, chunk 119\n",
            "File 01AN3S6T5PCLJNN6ZQMVFZZIMPQ7QTWMEY, chunk 0\n",
            "File 01AN3S6T5PCLJNN6ZQMVFZZIMPQ7QTWMEY, chunk 50\n",
            "File 01AN3S6T5PCLJNN6ZQMVFZZIMPQ7QTWMEY, chunk 100\n",
            "File 01AN3S6T5PCLJNN6ZQMVFZZIMPQ7QTWMEY, chunk 125\n",
            "File 01AN3S6TZ7CBBRLN4EHNAK7YK4EM2UIFUS, chunk 0\n",
            "File 01AN3S6TZ7CBBRLN4EHNAK7YK4EM2UIFUS, chunk 50\n",
            "File 01AN3S6TZ7CBBRLN4EHNAK7YK4EM2UIFUS, chunk 54\n",
            "File 01AN3S6T27MGH4MALVAZDL4I2P72ZSTYF2, chunk 0\n",
            "File 01AN3S6T27MGH4MALVAZDL4I2P72ZSTYF2, chunk 36\n"
          ]
        }
      ],
      "source": [
        "# Convert to embeddings using OpenAI\n",
        "\n",
        "# hold all pinecone payloads to be uploaded\n",
        "payloads = []\n",
        "\n",
        "# OpenAI embedding rate limit with 50% buffer\n",
        "rpm_limit_openai = 3000 * 0.75\n",
        "rpm_limit_pinecone = 3000 * 0.75\n",
        "openai_request = Api(average_rate_limit=rpm_limit_openai, max_retries=5)\n",
        "pinecone_request = Api(average_rate_limit=rpm_limit_pinecone, max_retries=3)\n",
        "for file in files:\n",
        "   doc_id = file['sharepoint_id']\n",
        "   payload = []\n",
        "   for i, chunk in enumerate(file['chunks']):\n",
        "      # create vector id\n",
        "      vec_id = str(uuid4())\n",
        "\n",
        "      # get vector representation of text chunk\n",
        "      chunk = chunk.encode(encoding='ASCII',errors='ignore').decode()  # fix any UNICODE errors\n",
        "      response = openai_request.send_request(openai.Embedding.create,input=chunk,engine='text-embedding-ada-002')\n",
        "      vector_value = response['data'][0]['embedding']  # this is a normal list\n",
        "\n",
        "      # vector metadata as dictionary\n",
        "      metadata = {\n",
        "         'document_id':doc_id,\n",
        "         'chunk_index': i\n",
        "      }\n",
        "\n",
        "      # create and append vector obj to the payload\n",
        "      vector_obj = (vec_id, vector_value, metadata)\n",
        "      payload.append(vector_obj)\n",
        "\n",
        "      # status update\n",
        "      if (i % 50 == 0 or i == len(file['chunks']) - 1):\n",
        "         print(f\"File {doc_id}, chunk {i}\")\n",
        "   \n",
        "   # append current payload to payloads\n",
        "   payloads.append(payload)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_json(\"test_payloads.json\",payloads)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "submitted pinecone payload 0\n",
            "submitted pinecone payload 1\n",
            "submitted pinecone payload 2\n",
            "submitted pinecone payload 3\n"
          ]
        }
      ],
      "source": [
        "# upload pinecone payloads\n",
        "for i, payload in enumerate(payloads):\n",
        "  # push batched payload to pinecone ensuring payload contains less than 80 vectors (abide by 2MB Pinecone limit)\n",
        "  pinecone_request.send_payload(vdb.upsert, payload, payload_length_limit=80)\n",
        "  print(f\"submitted pinecone payload {i}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9C8py6wQXE5_"
      },
      "outputs": [],
      "source": [
        "docsearch = FAISS.from_texts(texts, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpQ2VnBvXI2f"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_L_Ywm-iXLhm"
      },
      "outputs": [],
      "source": [
        "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3mtAth2jXNKO",
        "outputId": "4150fc7a-7705-41ec-a562-ac86e0cfb4f3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The authors of the article are Yuvanesh Anand, Zach Nussbaum, Brandon Duderstadt, Benjamin Schmidt and Andriy Mulyar.'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"who are the authors of the article?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RahXBIXjXO7X",
        "outputId": "96effd28-e864-4eea-fac0-b450cc04b56a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' $100'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"What was the cost of training the GPT4all model?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "EzNcvjRJXSZ4",
        "outputId": "15005165-937e-40ec-d08e-e142f4acdd65"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The model was trained with LoRA (Hu et al., 2021) on the 437,605 post-processed examples for four epochs. Detailed model hyper-parameters and training code can be found in the associated repository and model training log.'"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"How was the model trained?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Nhx-kpvAXUl3",
        "outputId": "e7bead62-1726-4e1d-c88e-528e5db1e9f9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The final training dataset contains 437,605 prompt-generation pairs.'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"what was the size of the training dataset?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "kIg91Z0YXXCB",
        "outputId": "01bf3ce5-0189-487a-b1b0-7bed1e2e12a2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' This model is different from other models because it is based on LLaMA, it is licensed only for research purposes, and it is trained on a dataset of post-processed examples. It also has a TSNE visualization of the final training data, and a zoomed-in view to show generations related to personal health and wellness.'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"How is this different from other models?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "D02sIID3XagO",
        "outputId": "df016d85-dedd-4800-8d1a-c872bfcb63a9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" I don't know.\""
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"What is Google Bard?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLynnMo0cj8m"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
