{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlorSbccWEDa"
      },
      "outputs": [],
      "source": [
        "%pip install langchain\n",
        "%pip install openai\n",
        "%pip install PyPDF2\n",
        "%pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nq0vKGFeW1KD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import pinecone\n",
        "from rate_limiter import Api\n",
        "from uuid import uuid4\n",
        "from dotenv import load_dotenv\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yKaKB_GjWKjL"
      },
      "outputs": [],
      "source": [
        "# Get your API keys from openai, you will need to create an account. \n",
        "load_dotenv()\n",
        "openai.organization = os.getenv(\"org_openai\")\n",
        "openai.api_key = os.getenv(\"key_openai\")\n",
        "\n",
        "pinecone.init(api_key=os.getenv(\"key_pinecone\"), environment=os.getenv(\"env_pinecone\"))\n",
        "vdb = pinecone.Index(os.getenv(\"idx_pinecone\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NalD3XkQWrJR"
      },
      "outputs": [],
      "source": [
        "# location of the pdf file/files.\n",
        "locations = [\n",
        "  'C:/Users/shaj6/Documents/Programming/repositories/chairGPT/assets/2022 Annual Report.pdf',\n",
        "  'C:/Users/shaj6/Documents/Programming/repositories/chairGPT/assets/2021 Annual Report.pdf',\n",
        "  'C:/Users/shaj6/Documents/Programming/repositories/chairGPT/assets/2021-lululemon-impact-report-03-09-22.pdf',\n",
        "  'C:/Users/shaj6/Documents/Programming/repositories/chairGPT/assets/code-of-conduct-november-2021-english.pdf'\n",
        "]\n",
        "readers = []\n",
        "for loc in locations:\n",
        "    readers.append(PdfReader(loc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwbEBhd0ZUfX",
        "outputId": "03542b02-bbc2-4c2a-def0-cae133e0b9f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<PyPDF2._reader.PdfReader at 0x14b73a6e710>,\n",
              " <PyPDF2._reader.PdfReader at 0x14b70e23f10>,\n",
              " <PyPDF2._reader.PdfReader at 0x14b60586350>,\n",
              " <PyPDF2._reader.PdfReader at 0x14b73a6fbe0>]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "readers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2VXlucKiW7bX"
      },
      "outputs": [],
      "source": [
        "# read data from the file and put them into a variable called raw_text\n",
        "files = []\n",
        "for idx, reader in enumerate(readers):\n",
        "    raw_text = ''\n",
        "    for i, page in enumerate(reader.pages):\n",
        "        text = page.extract_text()\n",
        "        if text:\n",
        "            raw_text += text\n",
        "    obj = {'raw_text':raw_text, 'file_location':locations[idx]}\n",
        "    files.append(obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97262\n"
          ]
        }
      ],
      "source": [
        "print(len(files[0]['raw_text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "VdXzkpf9XAfP"
      },
      "outputs": [],
      "source": [
        "# Chunk input text\n",
        "text_splitter = CharacterTextSplitter(      \n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "for file in files:\n",
        "    raw_text = file['raw_text']\n",
        "    file['chunks'] = text_splitter.split_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozkNTiNuZ0TX",
        "outputId": "dd800c23-e6fb-401a-ba22-1bb4a6b7d854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "338\n",
            "951.0118343195267\n"
          ]
        }
      ],
      "source": [
        "chunk_count = 0\n",
        "char_count = 0\n",
        "for file in files:\n",
        "  chunk_count += len(file['chunks'])\n",
        "  for chunk in file['chunks']:\n",
        "    char_count += len(chunk)\n",
        "print(chunk_count)\n",
        "print(char_count / chunk_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TcZUsQVyXBPX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File 9936b7ef-1470-4138-87ee-7de1557ea66e, chunk 0\n",
            "File 9936b7ef-1470-4138-87ee-7de1557ea66e, chunk 50\n",
            "File 9936b7ef-1470-4138-87ee-7de1557ea66e, chunk 100\n",
            "submitted pinecone\n",
            "File 72ce801e-9ecb-4e3d-96ff-de93dacf5ce8, chunk 0\n",
            "File 72ce801e-9ecb-4e3d-96ff-de93dacf5ce8, chunk 50\n",
            "File 72ce801e-9ecb-4e3d-96ff-de93dacf5ce8, chunk 100\n",
            "submitted pinecone\n",
            "File 30fd37c3-3f0f-41ef-8428-dbc1573801c3, chunk 0\n",
            "File 30fd37c3-3f0f-41ef-8428-dbc1573801c3, chunk 50\n",
            "submitted pinecone\n",
            "File b455d3bd-5f60-4b61-8fc9-e69e2c78a7e0, chunk 0\n",
            "submitted pinecone\n"
          ]
        }
      ],
      "source": [
        "# Convert to embeddings using OpenAI\n",
        "\n",
        "# OpenAI embedding rate limit with 50% buffer\n",
        "rpm_limit_openai = 3000 * 0.75\n",
        "rpm_limit_pinecone = 3000 * 0.75\n",
        "openai_request = Api(average_rate_limit=rpm_limit_openai, max_retries=5)\n",
        "pinecone_request = Api(average_rate_limit=rpm_limit_pinecone, max_retries=3)\n",
        "for file in files:\n",
        "   doc_id = str(uuid4())\n",
        "   payload = []\n",
        "   for i, chunk in enumerate(file['chunks']):\n",
        "      # create vector id\n",
        "      vec_id = str(uuid4())\n",
        "\n",
        "      # get vector representation of text chunk\n",
        "      chunk = chunk.encode(encoding='ASCII',errors='ignore').decode()  # fix any UNICODE errors\n",
        "      response = openai_request.send_request(openai.Embedding.create,input=chunk,engine='text-embedding-ada-002')\n",
        "      vector_value = response['data'][0]['embedding']  # this is a normal list\n",
        "\n",
        "      # vector metadata as dictionary\n",
        "      metadata = {\n",
        "         'document_id':doc_id,\n",
        "         'file_location': file['file_location'],\n",
        "         'chunk_index': i\n",
        "      }\n",
        "\n",
        "      # create and append vector obj to the payload\n",
        "      vector_obj = (vec_id, vector_value, metadata)\n",
        "      payload.append(vector_obj)\n",
        "\n",
        "      # status update\n",
        "      if (i % 50 == 0):\n",
        "         print(f\"File {doc_id}, chunk {i}\")\n",
        "   \n",
        "   # push batched payload to pinecone ensuring payload contains less than 80 vectors (abide by 2MB Pinecone limit)\n",
        "   pinecone_request.send_payload(vdb.upsert, payload, payload_length_limit=80)\n",
        "   print(\"submitted pinecone\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9C8py6wQXE5_"
      },
      "outputs": [],
      "source": [
        "docsearch = FAISS.from_texts(texts, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpQ2VnBvXI2f"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_L_Ywm-iXLhm"
      },
      "outputs": [],
      "source": [
        "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3mtAth2jXNKO",
        "outputId": "4150fc7a-7705-41ec-a562-ac86e0cfb4f3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The authors of the article are Yuvanesh Anand, Zach Nussbaum, Brandon Duderstadt, Benjamin Schmidt and Andriy Mulyar.'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"who are the authors of the article?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RahXBIXjXO7X",
        "outputId": "96effd28-e864-4eea-fac0-b450cc04b56a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' $100'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"What was the cost of training the GPT4all model?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "EzNcvjRJXSZ4",
        "outputId": "15005165-937e-40ec-d08e-e142f4acdd65"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The model was trained with LoRA (Hu et al., 2021) on the 437,605 post-processed examples for four epochs. Detailed model hyper-parameters and training code can be found in the associated repository and model training log.'"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"How was the model trained?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Nhx-kpvAXUl3",
        "outputId": "e7bead62-1726-4e1d-c88e-528e5db1e9f9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The final training dataset contains 437,605 prompt-generation pairs.'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"what was the size of the training dataset?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "kIg91Z0YXXCB",
        "outputId": "01bf3ce5-0189-487a-b1b0-7bed1e2e12a2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' This model is different from other models because it is based on LLaMA, it is licensed only for research purposes, and it is trained on a dataset of post-processed examples. It also has a TSNE visualization of the final training data, and a zoomed-in view to show generations related to personal health and wellness.'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"How is this different from other models?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "D02sIID3XagO",
        "outputId": "df016d85-dedd-4800-8d1a-c872bfcb63a9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" I don't know.\""
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"What is Google Bard?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLynnMo0cj8m"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
